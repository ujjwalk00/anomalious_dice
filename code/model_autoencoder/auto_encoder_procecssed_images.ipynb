{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:50:14.249761: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-04 15:50:14.249868: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    directory = \"../../processed_data/train_set/\"\n",
    "    data= []\n",
    "    label= []\n",
    "    for i in range(1, 7):\n",
    "        for filename in os.listdir(directory+str(i)):\n",
    "            if filename.endswith(\".png\"):\n",
    "                img = Image.open(directory+str(i)+\"/\"+filename)\n",
    "                data.append(np.array(img))\n",
    "                label.append(i-1)\n",
    "    print(len(data))\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6571\n"
     ]
    }
   ],
   "source": [
    "data, labels= create_dataset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6571, 128, 128)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = data/255\n",
    "labels= np.array(labels).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawings shape before :  (6571, 128, 128)\n",
      "Drawings shape after :  (6571, 128, 128, 1)\n",
      "Label shape :  (6571, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Drawings shape before : \", preprocessed_data.shape)\n",
    "preprocessed_data = np.expand_dims(preprocessed_data, axis=3)\n",
    "print(\"Drawings shape after : \", preprocessed_data.shape)\n",
    "print(\"Label shape : \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data in train/val/test set\n",
    "train_val_data, test_data, train_val_labels, test_labels = train_test_split(\n",
    "    preprocessed_data, \n",
    "    labels,\n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    train_val_data, \n",
    "    train_val_labels,\n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(128, 128, 1), name='input_layer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:33:50.733281: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-04 15:33:50.733401: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-04 15:33:50.733497: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (venkys-pc): /proc/driver/nvidia/version does not exist\n",
      "2022-02-04 15:33:50.735610: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Conv Block 1 -> BatchNorm->leaky Relu\n",
    "encoded = tf.keras.layers.Conv2D(32, kernel_size=3, strides= 1, padding='same', name='conv_1')(inputs)\n",
    "encoded = tf.keras.layers.BatchNormalization(name='batchnorm_1')(encoded)\n",
    "encoded = tf.keras.layers.LeakyReLU(name='leaky_relu_1')(encoded)\n",
    "# Conv Block 2 -> BatchNorm->leaky Relu\n",
    "encoded = tf.keras.layers.Conv2D(64, kernel_size=3, strides= 2, padding='same', name='conv_2')(encoded)\n",
    "encoded = tf.keras.layers.BatchNormalization(name='batchnorm_2')(encoded)\n",
    "encoded = tf.keras.layers.LeakyReLU(name='leaky_relu_2')(encoded)\n",
    "# Conv Block 3 -> BatchNorm->leaky Relu\n",
    "encoded = tf.keras.layers.Conv2D(64, kernel_size=3, strides=2, padding='same', name='conv_3')(encoded)\n",
    "encoded = tf.keras.layers.BatchNormalization(name='batchnorm_3')(encoded)\n",
    "encoded = tf.keras.layers.LeakyReLU(name='leaky_relu_3')(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeConv Block 1-> BatchNorm->leaky Relu\n",
    "decoded = tf.keras.layers.Conv2DTranspose(64, 3, strides= 1, padding='same',name='conv_transpose_1')(encoded)\n",
    "decoded = tf.keras.layers.BatchNormalization(name='batchnorm_4')(decoded)\n",
    "decoded = tf.keras.layers.LeakyReLU(name='leaky_relu_4')(decoded)\n",
    "# DeConv Block 2-> BatchNorm->leaky Relu\n",
    "decoded = tf.keras.layers.Conv2DTranspose(64, 3, strides= 2, padding='same', name='conv_transpose_2')(decoded)\n",
    "decoded = tf.keras.layers.BatchNormalization(name='batchnorm_5')(decoded)\n",
    "decoded = tf.keras.layers.LeakyReLU(name='leaky_relu_5')(decoded)\n",
    "# DeConv Block 3-> BatchNorm->leaky Relu\n",
    "decoded = tf.keras.layers.Conv2DTranspose(32, 3, 2, padding='same', name='conv_transpose_3')(decoded)\n",
    "decoded = tf.keras.layers.BatchNormalization(name='batchnorm_6')(decoded)\n",
    "decoded = tf.keras.layers.LeakyReLU(name='leaky_relu_6')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.keras.layers.Conv2DTranspose(1, 3, 1,padding='same', activation='sigmoid', name='conv_transpose_4')(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIMLoss(y_true, y_pred):\n",
    "  y_true = tf.cast(y_true,tf.float32)\n",
    "  y_pred = tf.cast(y_pred,tf.float32)\n",
    "  return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/pytorch/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "autoencoder = tf.keras.Model(inputs, outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(lr = 0.0005)\n",
    "autoencoder.compile(optimizer=optimizer, loss=SSIMLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 128, 128, 1)]     0         \n",
      "                                                                 \n",
      " conv_1 (Conv2D)             (None, 128, 128, 32)      320       \n",
      "                                                                 \n",
      " batchnorm_1 (BatchNormaliza  (None, 128, 128, 32)     128       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " leaky_relu_1 (LeakyReLU)    (None, 128, 128, 32)      0         \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " batchnorm_2 (BatchNormaliza  (None, 64, 64, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " leaky_relu_2 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batchnorm_3 (BatchNormaliza  (None, 32, 32, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " leaky_relu_3 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv_transpose_1 (Conv2DTra  (None, 32, 32, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batchnorm_4 (BatchNormaliza  (None, 32, 32, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " leaky_relu_4 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv_transpose_2 (Conv2DTra  (None, 64, 64, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batchnorm_5 (BatchNormaliza  (None, 64, 64, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " leaky_relu_5 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv_transpose_3 (Conv2DTra  (None, 128, 128, 32)     18464     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batchnorm_6 (BatchNormaliza  (None, 128, 128, 32)     128       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " leaky_relu_6 (LeakyReLU)    (None, 128, 128, 32)      0         \n",
      "                                                                 \n",
      " conv_transpose_4 (Conv2DTra  (None, 128, 128, 1)      289       \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,633\n",
      "Trainable params: 148,993\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "dot_img_file = '../assets/autoencoder.png'\n",
    "tf.keras.utils.plot_model(autoencoder, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:33:54.043521: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 344457216 exceeds 10% of free system memory.\n",
      "2022-02-04 15:33:54.596641: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 344457216 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "42/42 [==============================] - 744s 18s/step - loss: 0.3669 - val_loss: 0.4033\n",
      "Epoch 2/2\n",
      " 1/42 [..............................] - ETA: 1:24:04 - loss: 0.1344"
     ]
    }
   ],
   "source": [
    "hist=autoencoder.fit(train_val_data, train_val_data,\n",
    "                epochs=2,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_data, test_data), callbacks=[TensorBoard(log_dir='../assets/')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir='../assets/' #Specify the path in fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(test_data)\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(test_data[i].reshape(128, 128))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    plt.title(\"Original\")\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.imshow(decoded_imgs[i].reshape(128, 128))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_ano():\n",
    "    directory = \"../../processed_data/train_set/ano\"\n",
    "    data= []\n",
    "    label= []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".png\"):\n",
    "            img = Image.open(directory+\"/\"+filename)\n",
    "            data.append(np.array(img))\n",
    "                \n",
    "    print(len(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = create_dataset_ano()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = np.array(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = np.expand_dims(anomalies,axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(test_data)\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(test_data[i].reshape(128, 128))\n",
    "    plt.gray()\n",
    "    plt.title(\"Original\")\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    value_a = SSIMLoss(test_data[i], test_data[i])\n",
    "    label = 'SSIM Loss value: {:.3f}'\n",
    "    ax.set_xlabel(label.format(value_a) )\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.imshow(decoded_imgs[i].reshape(128, 128))\n",
    "    plt.gray()\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    value_a = SSIMLoss(decoded_imgs[i], test_data[i])\n",
    "    label = 'SSIM Loss value: {:.3f}'\n",
    "    ax.set_xlabel(label.format(value_a))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "n = 6  # how many encoded and decoded images we will display\n",
    "decoded_imgs= autoencoder.predict(test_data)\n",
    "decoded_mnistimgs= autoencoder.predict(anomalies)\n",
    "plt.figure(figsize=(20, 14), dpi=100)\n",
    "plt.subplots_adjust( wspace=0.1, hspace=0.07)\n",
    "plt_a=1\n",
    "for i in range(n):\n",
    "    # Original training dataset vs Original training\n",
    "    ax = plt.subplot(3, n, plt_a   )\n",
    "    plt.imshow(test_data[i].reshape(128,128))\n",
    "    ax.get_xaxis().set_visible(True)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    value_a = SSIMLoss(test_data[i], test_data[i])\n",
    "    ax.set_title(\"Original Image\")\n",
    "    label = 'SSIM Loss value: {:.3f}'\n",
    "    ax.set_xlabel(label.format(value_a) )\n",
    "    \n",
    "    # Reconstructed good data  vs Original training data\n",
    "    ax = plt.subplot(3, n, plt_a + n )\n",
    "    plt.imshow(decoded_imgs[i].reshape(128,128))\n",
    "    ax.get_xaxis().set_visible(True)\n",
    "    ax.get_yaxis().set_visible(False)    \n",
    "    value_a = SSIMLoss(decoded_imgs[i], test_data[i])\n",
    "    ax.set_title(\"Reconstructed Image\")\n",
    "    label = 'SSIM Loss value: {:.3f}'\n",
    "    ax.set_xlabel(label.format(value_a) )\n",
    "    \n",
    "    # Reconstructed anomalous data  vs Original training data\n",
    "    ax = plt.subplot(3, n, plt_a + 2*n)\n",
    "    plt.imshow(decoded_mnistimgs[i].reshape(128,128))\n",
    "    ax.get_xaxis().set_visible(True)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    value = SSIMLoss(decoded_mnistimgs[i], anomalies[i])\n",
    "    label = 'SSIM Loss value: {:.3f}'\n",
    "    ax.set_title(\"Anamolus Image \" )\n",
    "    ax.set_xlabel(label.format(value) )\n",
    "    plt_a+=1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a15777e5ebe9856c4bf3a427f20a1a9c5a7862cf6f1e835f61f16d20be88292"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
