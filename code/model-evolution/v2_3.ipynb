{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import TensorBoard\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "ROOT_FOLDER = \"..\\..\"\n",
    "DATA_FOLDER = os.path.join(ROOT_FOLDER, \"data\")\n",
    "TRAIN_FOLDER = os.path.join(DATA_FOLDER, \"train_set\")\n",
    "TEST_FOLDER = os.path.join(DATA_FOLDER, \"test_set\")\n",
    "PROCESSED_DATA = os.path.join(ROOT_FOLDER, 'processed_data')\n",
    "TEMPLATE_FOLDER = os.path.join(PROCESSED_DATA, 'templates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(processed_data=True, train=True, anomaly=False):\n",
    "    \"\"\"\n",
    "    gather all files from all folders in the train or test folder\n",
    "\n",
    "    :type: str representing which files we want\n",
    "    :return: list containing\n",
    "    \"\"\"\n",
    "\n",
    "    # define whether to use train or test set\n",
    "    if train:\n",
    "        data_set = 'train_set'\n",
    "    else:\n",
    "        data_set = 'test_set'\n",
    "\n",
    "    # define whether to use processed or original data\n",
    "    if processed_data:\n",
    "        data_folder = PROCESSED_DATA\n",
    "        templates = [1,2,3,4,5,6]\n",
    "    else:\n",
    "        data_folder = DATA_FOLDER\n",
    "        template_folder = os.path.join(DATA_FOLDER, data_set)\n",
    "        templates = os.listdir(template_folder)\n",
    "\n",
    "    # choose anomalous dice if set as parameter\n",
    "    if anomaly:\n",
    "        templates = [\"ano\"]\n",
    "\n",
    "    # initialize return types\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for template in templates:\n",
    "        # get the folder name, all filenames inside it, and make a list of all the image files inside\n",
    "        train_folder = os.path.join(data_folder, data_set)\n",
    "        folder = os.path.join(train_folder, str(template))\n",
    "        filenames = os.listdir(folder)\n",
    "        files = [file for file in filenames if \".png\" in file]\n",
    "\n",
    "        for file in files:\n",
    "            img = Image.open(os.path.join(folder,file))\n",
    "            data.append(np.array(img))\n",
    "            label.append(template)\n",
    "            \n",
    "    label= np.array(label).reshape(-1,1)\n",
    "\n",
    "    return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIMLoss(y_true, y_pred):\n",
    "  y_true = tf.cast(y_true,tf.float32)\n",
    "  y_pred = tf.cast(y_pred,tf.float32)\n",
    "  return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinaryCrossEntropy(y_true, y_pred):\n",
    "    y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "    term_0 = (1-y_true) * np.log(1-y_pred + 1e-7)\n",
    "    term_1 = y_true * np.log(y_pred + 1e-7)\n",
    "    return tf.reduce_mean(-np.mean(term_0+term_1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_preprocess_dataset(data, split = True):\n",
    "    data = np.array(data)\n",
    "    preprocessed_data = data/255\n",
    "    preprocessed_data = np.expand_dims(preprocessed_data, axis=3)\n",
    "\n",
    "    if not split:\n",
    "        return preprocessed_data, _, _, _, _, _, _, _\n",
    "\n",
    "    # split data in train/val/test set\n",
    "    train_val_data, test_data, train_val_labels, test_labels = train_test_split(\n",
    "        preprocessed_data, \n",
    "        labels,\n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "        train_val_data, \n",
    "        train_val_labels,\n",
    "        test_size=0.3, \n",
    "        random_state=42, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    return train_val_data, test_data, train_val_labels, test_labels, train_data, val_data, train_labels, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather, process and preprocess all training data.\n",
    "\n",
    "data, labels = create_dataset(processed_data=True, train=True)\n",
    "train_val_data, test_data, train_val_labels, test_labels, train_data, val_data, train_labels, val_labels = split_and_preprocess_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather, process and preprocess all training data.\n",
    "\n",
    "anomalies, _ = create_dataset(processed_data=True, train=True, anomaly=True)\n",
    "anomalies, _, _, _, _, _, _, _ = split_and_preprocess_dataset(anomalies, split = False)\n",
    "#anomalies = [x.reshape(128, 128, 1) for x in anomalies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the unseen testing data set\n",
    "\n",
    "test_normals, _ = create_dataset(processed_data=True, train=False, anomaly=False)\n",
    "test_normals, _, _, _, _, _, _, _ = split_and_preprocess_dataset(test_normals, split = False)\n",
    "\n",
    "test_anomalies, _ = create_dataset(processed_data=True, train=False, anomaly=True)\n",
    "test_anomalies, _, _, _, _, _, _, _ = split_and_preprocess_dataset(test_anomalies, split = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper_params\n",
    "\n",
    "original_dim = 128 * 128\n",
    "intermediate_dim = 64\n",
    "latent_dim = 2\n",
    "\n",
    "inputs = keras.Input(shape=(original_dim,))\n",
    "h = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = layers.Dense(latent_dim)(h)\n",
    "z_log_sigma = layers.Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "# Create decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = layers.Dense(original_dim, activation='sigmoid')(x)\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
    "reconstruction_loss *= original_dim\n",
    "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reshape((len(train_data), np.prod(train_data.shape[1:])))\n",
    "val_data = val_data.reshape((len(val_data), np.prod(val_data.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/115 [..............................] - ETA: 13s - loss: 11365.6562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aubin\\anaconda3\\envs\\dicething\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4526: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 13s 115ms/step - loss: 6421.1821 - val_loss: 5502.4756\n",
      "Epoch 2/10\n",
      "115/115 [==============================] - 13s 114ms/step - loss: 5288.0317 - val_loss: 5162.8130\n",
      "Epoch 3/10\n",
      "115/115 [==============================] - 13s 114ms/step - loss: 5119.6475 - val_loss: 5064.8281\n",
      "Epoch 4/10\n",
      "115/115 [==============================] - 11s 97ms/step - loss: 5046.6553 - val_loss: 5011.3726\n",
      "Epoch 5/10\n",
      "115/115 [==============================] - 10s 89ms/step - loss: 4998.0820 - val_loss: 4979.0469\n",
      "Epoch 6/10\n",
      "115/115 [==============================] - 12s 101ms/step - loss: 4964.9580 - val_loss: 4947.1162\n",
      "Epoch 7/10\n",
      "115/115 [==============================] - 9s 82ms/step - loss: 4940.4312 - val_loss: 4920.6567\n",
      "Epoch 8/10\n",
      "115/115 [==============================] - 9s 80ms/step - loss: 4915.6772 - val_loss: 4896.7339\n",
      "Epoch 9/10\n",
      "115/115 [==============================] - 10s 87ms/step - loss: 4899.8945 - val_loss: 4879.1870\n",
      "Epoch 10/10\n",
      "115/115 [==============================] - 10s 88ms/step - loss: 4882.6763 - val_loss: 4889.7310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27d92dd0d30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(train_data, train_data,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        validation_data=(val_data, val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"encoder\" (type Functional).\n\nInput 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (32,)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(32,), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m autoencoder\u001b[39m.\u001b[39;49mpredict(train_data[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dicething\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dicething\\lib\\site-packages\\keras\\engine\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=224'>225</a>\u001b[0m   ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=225'>226</a>\u001b[0m   \u001b[39mif\u001b[39;00m ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ndim \u001b[39m<\u001b[39m spec\u001b[39m.\u001b[39mmin_ndim:\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=226'>227</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=227'>228</a>\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=228'>229</a>\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexpected min_ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mmin_ndim\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=229'>230</a>\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfound ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=230'>231</a>\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=231'>232</a>\u001b[0m \u001b[39m# Check dtype.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=232'>233</a>\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"encoder\" (type Functional).\n\nInput 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (32,)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(32,), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "autoencoder.predict(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"encoder\" (type Functional).\n\nInput 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (32,)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(32,), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m decoded_mnistimgs \u001b[39m=\u001b[39m []\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[1;32m---> 12\u001b[0m     reduced \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39;49mpredict(train_data[i])\n\u001b[0;32m     13\u001b[0m     decoded_imgs\u001b[39m.\u001b[39mappend(reduced)\n\u001b[0;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m     \u001b[39m# Original training dataset vs Original training\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dicething\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dicething\\lib\\site-packages\\keras\\engine\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=224'>225</a>\u001b[0m   ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=225'>226</a>\u001b[0m   \u001b[39mif\u001b[39;00m ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ndim \u001b[39m<\u001b[39m spec\u001b[39m.\u001b[39mmin_ndim:\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=226'>227</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=227'>228</a>\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=228'>229</a>\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexpected min_ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mmin_ndim\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=229'>230</a>\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfound ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=230'>231</a>\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=231'>232</a>\u001b[0m \u001b[39m# Check dtype.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/dicething/lib/site-packages/keras/engine/input_spec.py?line=232'>233</a>\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"encoder\" (type Functional).\n\nInput 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (32,)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(32,), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "n = 6  # how many encoded and decoded images we will display\n",
    "\n",
    "plt.figure(figsize=(20, 14), dpi=100)\n",
    "plt.subplots_adjust( wspace=0.1, hspace=0.07)\n",
    "plt_a=1\n",
    "\n",
    "decoded_imgs = []\n",
    "decoded_mnistimgs = []\n",
    "\n",
    "for i in range(n):\n",
    "    reduced = autoencoder.predict(train_data[i])\n",
    "    decoded_imgs.append(reduced)\n",
    "\n",
    "for i in range(n):\n",
    "\n",
    "    # Original training dataset vs Original training\n",
    "    ax = plt.subplot(3, n, plt_a   )\n",
    "    plt.imshow(test_data[i].reshape(128,128), cmap=\"gray\")\n",
    "    ax.get_xaxis().set_visible(True)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    value_a = SSIMLoss(test_data[i], test_data[i])\n",
    "    ax.set_title(\"Original Image\")\n",
    "    label = 'SSIM Loss value: {:.3f}'\n",
    "    ax.set_xlabel(label.format(value_a) )\n",
    "\n",
    "    # Reconstructed anomalous data  vs Original training data\n",
    "    ax = plt.subplot(3, n, plt_a + n)\n",
    "    img_2 = decoded_imgs[i].reshape(128,128,1)\n",
    "    plt.imshow(img_2.reshape(128,128), cmap=\"gray\")\n",
    "    ax.get_xaxis().set_visible(True)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    value = SSIMLoss(img_2, test_data[i])\n",
    "    label = 'SSIM Loss value: {:.3f}'\n",
    "    ax.set_title(\"Anamolus Image \" )\n",
    "    ax.set_xlabel(label.format(value) )\n",
    "    plt_a+=1\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a15777e5ebe9856c4bf3a427f20a1a9c5a7862cf6f1e835f61f16d20be88292"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('computer_vision': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
