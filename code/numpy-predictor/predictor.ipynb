{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "ROOT_FOLDER = \"..\\..\"\n",
    "DATA_FOLDER = os.path.join(ROOT_FOLDER, \"data\")\n",
    "TRAIN_FOLDER = os.path.join(DATA_FOLDER, \"train_set\")\n",
    "TEST_FOLDER = os.path.join(DATA_FOLDER, \"test_set\")\n",
    "PROCESSED_DATA = os.path.join(ROOT_FOLDER, 'processed_data')\n",
    "TEMPLATE_FOLDER = os.path.join(PROCESSED_DATA, 'templates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_template(input_path, template_path, category, method = \"pixel_count\", debug_mode = False):\n",
    "    \"\"\"\n",
    "    function that matches the image to a template.\n",
    "\n",
    "    :input_path: str path to image \n",
    "    :template_path: str path to template  \n",
    "    :method: str identifier of what method to use for matching\n",
    "    :debug_mode: decides whether to return additional debugging data\n",
    "    :return: an error variable dependent on the chosen method and debugging info or None depending on mode.\n",
    "    \"\"\"\n",
    "\n",
    "    # sometimes the category is given as as \n",
    "     \n",
    "    category_converter = {'00':1, '01':2, '02':2, '03':3, '04':3, '05':4, '06':5, '07':6, '08':6, '09':6, '10':6}\n",
    "    if category in list(category_converter.keys()):\n",
    "        category = category_converter[category]\n",
    "\n",
    "        stored_parameters = {\n",
    "            1: 50,\n",
    "            2: 50,\n",
    "            3: 50,\n",
    "            4: 50,\n",
    "            5: 50,\n",
    "            6: 25\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        category = int(category)\n",
    "\n",
    "        stored_parameters = {\n",
    "            1: 35,\n",
    "            2: 25,\n",
    "            3: 50,\n",
    "            4: 75,\n",
    "            5: 75,\n",
    "            6: 100\n",
    "        }\n",
    "\n",
    "    # load in image and template\n",
    "    sample_image = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "    template_image = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if method == \"pixel_count\":\n",
    "        # important for this method is that the oprder of subtracting does matter. \n",
    "        # because a 2 will have holes in the same spots as a 5 and will register a false positive\n",
    "\n",
    "        thresh = stored_parameters[category]\n",
    "\n",
    "        diff = template_image - sample_image\n",
    "        errors = (diff > thresh).sum()\n",
    "\n",
    "        if debug_mode:\n",
    "            return errors, sample_image, template_image\n",
    "\n",
    "        return errors, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_samples(processed_data=True):\n",
    "    \"\"\"\n",
    "    gather all files from all folders\n",
    "\n",
    "    :type: str representing which files we want\n",
    "    :return: list containg a list for each sample with the path and the category\n",
    "    \"\"\"\n",
    "\n",
    "    if processed_data:\n",
    "        data_folder = PROCESSED_DATA\n",
    "        templates = [1,2,3,4,5,6]\n",
    "    else:\n",
    "        data_folder = DATA_FOLDER\n",
    "        template_folder = os.path.join(DATA_FOLDER, \"train_set\")\n",
    "        templates = os.listdir(template_folder)\n",
    "\n",
    "    all_files = []\n",
    "\n",
    "    for template in templates:\n",
    "\n",
    "        # get the folder name, all filenames inside it, and make a list of all the image files inside\n",
    "        train_folder = os.path.join(data_folder, 'train_set')\n",
    "        folder = os.path.join(train_folder, str(template))\n",
    "        filenames = os.listdir(folder)\n",
    "        files = [file for file in filenames if \".png\" in file]\n",
    "\n",
    "        for file in files:\n",
    "            random_file_path = os.path.join(folder,file)\n",
    "\n",
    "            all_files.append([random_file_path, template])\n",
    "\n",
    "    return all_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = gather_samples()\n",
    "\n",
    "df = pd.DataFrame(all_files)\n",
    "df = df.set_axis(['path', 'category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code below calculates the errors for each of the categories.\n",
    "\n",
    "def train_model(processed_data = True):\n",
    "    \"\"\"\n",
    "    A very basic model where each sample n has x features that represent the error per category\n",
    "    calculated by the match template - pixel count method.\n",
    "\n",
    "    :returns: a list containing a list for each sample containing x errors, 1 for each category. \n",
    "    \"\"\"\n",
    "\n",
    "    if processed_data:\n",
    "        all_templates = os.listdir(TEMPLATE_FOLDER)\n",
    "    else:\n",
    "        template_folder = os.path.join(DATA_FOLDER, \"templates\")\n",
    "        all_templates = os.listdir(template_folder)\n",
    "        all_templates.remove('ano.png')\n",
    "    \n",
    "    all_errors = []\n",
    "    # for each sample\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        sample_path = row['path']\n",
    "        errors_per_row = []\n",
    "\n",
    "        for idx, template in enumerate(all_templates):\n",
    "            category = template\n",
    "            category = category.replace(\".png\",\"\")\n",
    "            template_file = template\n",
    "            correct_template_path = os.path.join(template_folder, template_file)\n",
    "            errors, _, _ = match_template(sample_path, correct_template_path, category)\n",
    "            errors_per_row.append(errors)\n",
    "        all_errors.append(errors_per_row)\n",
    "\n",
    "    return all_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors = train_model()\n",
    "\n",
    "results = pd.DataFrame(all_errors)\n",
    "results = results.transpose().reset_index(drop=True).transpose()\n",
    "results = results.set_axis([1,2,3,4,5,6], axis=1)\n",
    "\n",
    "df = pd.concat([df,results], axis=1)\n",
    "df.to_csv('results.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5077.420624151968 5529.879499485773\n",
      "5736.462890625 6387.752478817379\n",
      "5769.956910569105 6368.983710915559\n",
      "5832.717811158798 6556.790920375953\n",
      "5771.823399558499 6686.0946160635485\n",
      "5733.020665901263 7280.811141022986\n"
     ]
    }
   ],
   "source": [
    "thresholds = {}\n",
    "\n",
    "for x in range(6):\n",
    "    col = x+1\n",
    "\n",
    "    correct = df.loc[df.category == col]\n",
    "    false = df.loc[df.category != col]\n",
    "    \n",
    "    print(correct[col].mean(), false[col].mean())\n",
    "\n",
    "    thresholds[col] = (correct[col].mean() + false[col].mean())/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 5303.65006181887,\n",
       " 2: 6062.10768472119,\n",
       " 3: 6069.470310742332,\n",
       " 4: 6194.754365767376,\n",
       " 5: 6228.959007811023,\n",
       " 6: 6506.915903462124}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = 0\n",
    "for key, val in thresholds.items():\n",
    "    average += val\n",
    "\n",
    "average = average - 500\n",
    "average = average / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all anomaly files \n",
    "anom_files = []\n",
    "\n",
    "train_folder = os.path.join(PROCESSED_DATA, 'train_set')\n",
    "folder = os.path.join(train_folder, \"ano\")\n",
    "filenames = os.listdir(folder)\n",
    "files = [file for file in filenames if \".png\" in file]\n",
    "\n",
    "for file in files:\n",
    "    random_file_path = os.path.join(folder,file)\n",
    "\n",
    "    anom_files.append([random_file_path, template])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "total_detection = 0\n",
    "\n",
    "for anom in anom_files:\n",
    "    prediction = 0\n",
    "    for idx, template in enumerate(all_templates):\n",
    "        category = idx + 1\n",
    "        template_file = template\n",
    "        correct_template_path = os.path.join(TEMPLATE_FOLDER, template_file)\n",
    "        errors, _, _ = match_template(anom[0], correct_template_path, category)\n",
    "        if errors > average:\n",
    "            prediction = 1\n",
    "    predictions.append(prediction)\n",
    "\n",
    "correct_predictions = [1 for x in predictions]\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(correct_predictions, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = [1 for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(correct_predictions, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try with the old images\n",
    "all_files = gather_samples(processed_data=False)\n",
    "\n",
    "df = pd.DataFrame(all_files)\n",
    "df = df.set_axis(['path', 'category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors = train_model(processed_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>category</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\data\\train_set\\00\\16_09_21_00_000.png</td>\n",
       "      <td>00</td>\n",
       "      <td>5212</td>\n",
       "      <td>6575</td>\n",
       "      <td>6435</td>\n",
       "      <td>7241</td>\n",
       "      <td>6962</td>\n",
       "      <td>7876</td>\n",
       "      <td>8134</td>\n",
       "      <td>10128</td>\n",
       "      <td>9965</td>\n",
       "      <td>10064</td>\n",
       "      <td>10176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data\\train_set\\00\\16_09_21_00_001.png</td>\n",
       "      <td>00</td>\n",
       "      <td>7718</td>\n",
       "      <td>7810</td>\n",
       "      <td>8564</td>\n",
       "      <td>8488</td>\n",
       "      <td>9142</td>\n",
       "      <td>9239</td>\n",
       "      <td>9321</td>\n",
       "      <td>12242</td>\n",
       "      <td>12369</td>\n",
       "      <td>11866</td>\n",
       "      <td>12491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\data\\train_set\\00\\16_09_21_00_002.png</td>\n",
       "      <td>00</td>\n",
       "      <td>2547</td>\n",
       "      <td>5038</td>\n",
       "      <td>4951</td>\n",
       "      <td>5853</td>\n",
       "      <td>4696</td>\n",
       "      <td>7310</td>\n",
       "      <td>7227</td>\n",
       "      <td>8043</td>\n",
       "      <td>8479</td>\n",
       "      <td>8138</td>\n",
       "      <td>8663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\data\\train_set\\00\\16_09_21_00_003.png</td>\n",
       "      <td>00</td>\n",
       "      <td>2329</td>\n",
       "      <td>4782</td>\n",
       "      <td>4542</td>\n",
       "      <td>5059</td>\n",
       "      <td>4336</td>\n",
       "      <td>6893</td>\n",
       "      <td>6905</td>\n",
       "      <td>7885</td>\n",
       "      <td>8254</td>\n",
       "      <td>8400</td>\n",
       "      <td>8276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\data\\train_set\\00\\16_09_21_00_004.png</td>\n",
       "      <td>00</td>\n",
       "      <td>3795</td>\n",
       "      <td>5476</td>\n",
       "      <td>5726</td>\n",
       "      <td>6524</td>\n",
       "      <td>5837</td>\n",
       "      <td>7495</td>\n",
       "      <td>7561</td>\n",
       "      <td>9945</td>\n",
       "      <td>9539</td>\n",
       "      <td>9579</td>\n",
       "      <td>9929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          path category     1     2     3  \\\n",
       "0  ..\\..\\data\\train_set\\00\\16_09_21_00_000.png       00  5212  6575  6435   \n",
       "1  ..\\..\\data\\train_set\\00\\16_09_21_00_001.png       00  7718  7810  8564   \n",
       "2  ..\\..\\data\\train_set\\00\\16_09_21_00_002.png       00  2547  5038  4951   \n",
       "3  ..\\..\\data\\train_set\\00\\16_09_21_00_003.png       00  2329  4782  4542   \n",
       "4  ..\\..\\data\\train_set\\00\\16_09_21_00_004.png       00  3795  5476  5726   \n",
       "\n",
       "      4     5     6     7      8      9     10     11  \n",
       "0  7241  6962  7876  8134  10128   9965  10064  10176  \n",
       "1  8488  9142  9239  9321  12242  12369  11866  12491  \n",
       "2  5853  4696  7310  7227   8043   8479   8138   8663  \n",
       "3  5059  4336  6893  6905   7885   8254   8400   8276  \n",
       "4  6524  5837  7495  7561   9945   9539   9579   9929  "
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(all_errors)\n",
    "results = results.transpose().reset_index(drop=True).transpose()\n",
    "results = results.set_axis([1,2,3,4,5,6,7,8,9,10,11], axis=1)\n",
    "\n",
    "df = pd.concat([df,results], axis=1)\n",
    "df.to_csv('results.csv')\n",
    "df = df[df.category != \"ano\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'] = pd.to_numeric(df.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8503.953703703704 8180.433758912286\n",
      "9335.028925619834 9155.987021521274\n",
      "9064.86303630363 9183.330427493713\n",
      "9822.004807692309 9802.97948545485\n",
      "9311.492489270386 9663.397942897676\n",
      "8987.030905077263 10396.141394527802\n",
      "10920.125907990314 10235.96346216304\n",
      "10825.793969849246 12040.647011177709\n",
      "10877.939334637966 11959.446864686468\n",
      "10932.016666666666 11982.497317509347\n"
     ]
    }
   ],
   "source": [
    "thresholds = {}\n",
    "\n",
    "for x in range(10):\n",
    "    col = x+1\n",
    "\n",
    "    correct = df.loc[df.category == col]\n",
    "    false = df.loc[df.category != col]\n",
    "    \n",
    "    print(correct[col].mean(), false[col].mean())\n",
    "\n",
    "    thresholds[col] = (correct[col].mean() + false[col].mean())/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 8342.193731307994,\n",
       " 2: 9245.507973570555,\n",
       " 3: 9124.096731898671,\n",
       " 4: 9812.492146573579,\n",
       " 5: 9487.44521608403,\n",
       " 6: 9691.586149802533,\n",
       " 7: 10578.044685076677,\n",
       " 8: 11433.220490513479,\n",
       " 9: 11418.693099662218,\n",
       " 10: 11457.256992088007}"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = 0\n",
    "for key, val in thresholds.items():\n",
    "    average += val\n",
    "\n",
    "average = average - 500\n",
    "average = average / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10009.053721657776"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all anomaly files \n",
    "anom_files = []\n",
    "\n",
    "train_folder = os.path.join(DATA_FOLDER, 'train_set')\n",
    "folder = os.path.join(train_folder, \"ano\")\n",
    "filenames = os.listdir(folder)\n",
    "files = [file for file in filenames if \".png\" in file]\n",
    "\n",
    "for file in files:\n",
    "    random_file_path = os.path.join(folder,file)\n",
    "\n",
    "    anom_files.append([random_file_path, template])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4042553191489362"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_folder = os.path.join(DATA_FOLDER, \"templates\")\n",
    "all_templates = os.listdir(template_folder)\n",
    "all_templates.remove('ano.png')\n",
    "\n",
    "predictions = []\n",
    "total_detection = 0\n",
    "\n",
    "for anom in anom_files:\n",
    "    prediction = 0\n",
    "    for idx, template in enumerate(all_templates):\n",
    "        category = template\n",
    "        category = category.replace('.png', '')\n",
    "        template_file = template\n",
    "        correct_template_path = os.path.join(template_folder, template_file)\n",
    "        errors, _, _ = match_template(anom[0], correct_template_path, category)\n",
    "        if errors > average:\n",
    "            prediction = 1\n",
    "    predictions.append(prediction)\n",
    "\n",
    "correct_predictions = [1 for x in predictions]\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(correct_predictions, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fd65506147fe4f66ad28d9813792ae1a36a4062b2d7e2e39e3b9ce41d2e0a83"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('dicething': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
