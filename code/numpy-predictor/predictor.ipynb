{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "ROOT_FOLDER = \"..\\..\"\n",
    "DATA_FOLDER = os.path.join(ROOT_FOLDER, \"data\")\n",
    "TRAIN_FOLDER = os.path.join(DATA_FOLDER, \"train_set\")\n",
    "TEST_FOLDER = os.path.join(DATA_FOLDER, \"test_set\")\n",
    "PROCESSED_DATA = os.path.join(ROOT_FOLDER, 'processed_data')\n",
    "TEMPLATE_FOLDER = os.path.join(PROCESSED_DATA, 'templates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_template(\n",
    "    input_path,\n",
    "    template_path,\n",
    "    category,\n",
    "    path=True,\n",
    "    method=\"pixel_count\",\n",
    "    debug_mode=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    function that matches the image to a template.\n",
    "\n",
    "    :input_path: str path to image\n",
    "    :template_path: str path to template\n",
    "    :method: str identifier of what method to use for matching\n",
    "    :debug_mode: decides whether to return additional debugging data\n",
    "    :return: an error variable dependent on the chosen method and debugging info or None depending on mode.\n",
    "    \"\"\"\n",
    "\n",
    "    # sometimes the category is given as as\n",
    "\n",
    "    category_converter = {\n",
    "        \"00\": 1,\n",
    "        \"01\": 2,\n",
    "        \"02\": 2,\n",
    "        \"03\": 3,\n",
    "        \"04\": 3,\n",
    "        \"05\": 4,\n",
    "        \"06\": 5,\n",
    "        \"07\": 6,\n",
    "        \"08\": 6,\n",
    "        \"09\": 6,\n",
    "        \"10\": 6,\n",
    "    }\n",
    "    if category in list(category_converter.keys()):\n",
    "        category = category_converter[category]\n",
    "\n",
    "        stored_parameters = {1: 50, 2: 50, 3: 50, 4: 50, 5: 50, 6: 25}\n",
    "\n",
    "    else:\n",
    "        category = int(category)\n",
    "\n",
    "        stored_parameters = {1: 35, 2: 25, 3: 50, 4: 75, 5: 75, 6: 100}\n",
    "\n",
    "    if path:\n",
    "        # load in image and template\n",
    "        sample_image = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        sample_image = np.array(input_path)\n",
    "\n",
    "    template_image = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if method == \"pixel_count\":\n",
    "        # important for this method is that the oprder of subtracting does matter.\n",
    "        # because a 2 will have holes in the same spots as a 5 and will register a false positive\n",
    "\n",
    "        thresh = stored_parameters[category]\n",
    "\n",
    "        diff = template_image - sample_image\n",
    "        errors = (diff > thresh).sum()\n",
    "\n",
    "        if debug_mode:\n",
    "            return errors, sample_image, template_image\n",
    "\n",
    "        return errors, None, None\n",
    "\n",
    "    elif method == \"MSE\":\n",
    "        # iThe next method uses MSE to calculate the distances between to images\n",
    "\n",
    "        mse = np.square(np.subtract(template_image, sample_image)).mean()\n",
    "\n",
    "        if debug_mode:\n",
    "            return mse, sample_image, template_image\n",
    "\n",
    "        return mse, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_model(image, path=True, thresholds=None):\n",
    "    \"\"\"\n",
    "    predicts whether a dice is an anomaly or not\n",
    "\n",
    "    :image: str path to image file\n",
    "    :thresholds: dict containg custom thresholds foe each category, load it in from thresholds.pickle\n",
    "    :return: return a predictions overall, and a prediction list as to what class it may belong\n",
    "    \"\"\"\n",
    "\n",
    "    all_templates = [\"1.png\", \"2.png\", \"3.png\", \"4.png\", \"5.png\", \"6.png\"]\n",
    "\n",
    "    predicted = 0\n",
    "    predictions = []\n",
    "\n",
    "    if not thresholds:\n",
    "        thresholds = {\n",
    "            1: 62.02780473883087,\n",
    "            2: 60.430025740950214,\n",
    "            3: 66.30725609998866,\n",
    "            4: 69.93280870737878,\n",
    "            5: 74.30941474250847,\n",
    "            6: 82.75002536741725,\n",
    "        }\n",
    "\n",
    "    for idx, template in enumerate(all_templates):\n",
    "        # this should link to a folder containg the templates.\n",
    "        template_path = os.path.join(TEMPLATE_FOLDER, template)\n",
    "\n",
    "        errors, _, _ = match_template(\n",
    "            image, template_path, path=path, category=1, method=\"MSE\"\n",
    "        )\n",
    "        thresh = thresholds[idx + 1]\n",
    "\n",
    "        print(errors, thresh)\n",
    "\n",
    "        if errors > thresh:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "\n",
    "    if sum(predictions) >= 6:\n",
    "        predicted = 1\n",
    "\n",
    "    return predicted, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.1368408203125\n",
      "35.5228271484375 62.02780473883087\n",
      "81.18719482421875\n",
      "52.44366455078125 60.430025740950214\n",
      "89.55743408203125\n",
      "50.23321533203125 66.30725609998866\n",
      "88.81103515625\n",
      "56.977294921875 69.93280870737878\n",
      "95.5618896484375\n",
      "54.762451171875 74.30941474250847\n",
      "94.6248779296875\n",
      "62.4407958984375 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "78.36871337890625\n",
      "48.64520263671875 62.02780473883087\n",
      "82.2784423828125\n",
      "58.8927001953125 60.430025740950214\n",
      "87.320556640625\n",
      "58.71630859375 66.30725609998866\n",
      "91.93353271484375\n",
      "61.30950927734375 69.93280870737878\n",
      "96.21563720703125\n",
      "61.97613525390625 74.30941474250847\n",
      "89.57550048828125\n",
      "65.86077880859375 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "27.27667236328125\n",
      "36.89691162109375 62.02780473883087\n",
      "59.2489013671875\n",
      "45.8560791015625 60.430025740950214\n",
      "55.837890625\n",
      "37.24365234375 66.30725609998866\n",
      "80.65399169921875\n",
      "54.30267333984375 69.93280870737878\n",
      "81.60797119140625\n",
      "49.84185791015625 74.30941474250847\n",
      "93.17095947265625\n",
      "53.51910400390625 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "24.442138671875\n",
      "44.870361328125 62.02780473883087\n",
      "62.83624267578125\n",
      "48.71258544921875 60.430025740950214\n",
      "68.14398193359375\n",
      "47.27459716796875 66.30725609998866\n",
      "80.1007080078125\n",
      "54.0482177734375 69.93280870737878\n",
      "76.7578125\n",
      "53.3214111328125 74.30941474250847\n",
      "89.94580078125\n",
      "53.9534912109375 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "52.20257568359375\n",
      "40.58465576171875 62.02780473883087\n",
      "83.0966796875\n",
      "54.9879150390625 60.430025740950214\n",
      "86.4200439453125\n",
      "52.6280517578125 66.30725609998866\n",
      "89.04864501953125\n",
      "57.31439208984375 69.93280870737878\n",
      "88.97137451171875\n",
      "54.35064697265625 74.30941474250847\n",
      "94.98748779296875\n",
      "63.11322021484375 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "70.07958984375\n",
      "38.886474609375 62.02780473883087\n",
      "79.16119384765625\n",
      "55.22686767578125 60.430025740950214\n",
      "87.81268310546875\n",
      "52.99249267578125 66.30725609998866\n",
      "85.5662841796875\n",
      "57.1875 69.93280870737878\n",
      "93.426513671875\n",
      "54.500732421875 74.30941474250847\n",
      "92.927001953125\n",
      "63.839111328125 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "48.54571533203125\n",
      "39.51080322265625 62.02780473883087\n",
      "73.9241943359375\n",
      "55.0172119140625 60.430025740950214\n",
      "86.12255859375\n",
      "52.82177734375 66.30725609998866\n",
      "84.00115966796875\n",
      "58.03778076171875 69.93280870737878\n",
      "90.58013916015625\n",
      "54.37799072265625 74.30941474250847\n",
      "93.20562744140625\n",
      "63.73602294921875 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "56.93902587890625\n",
      "40.91400146484375 62.02780473883087\n",
      "76.9425048828125\n",
      "56.1021728515625 60.430025740950214\n",
      "84.359619140625\n",
      "53.453857421875 66.30725609998866\n",
      "84.20697021484375\n",
      "57.74908447265625 69.93280870737878\n",
      "90.19219970703125\n",
      "55.11822509765625 74.30941474250847\n",
      "92.03643798828125\n",
      "64.07647705078125 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "20.7752685546875\n",
      "42.76171875 62.02780473883087\n",
      "52.99749755859375\n",
      "53.01007080078125 60.430025740950214\n",
      "47.89898681640625\n",
      "43.94256591796875 66.30725609998866\n",
      "79.246337890625\n",
      "56.672119140625 69.93280870737878\n",
      "72.5596923828125\n",
      "49.478515625 74.30941474250847\n",
      "83.6695556640625\n",
      "55.5845947265625 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "42.667724609375\n",
      "37.0281982421875 62.02780473883087\n",
      "63.04620361328125\n",
      "48.95648193359375 60.430025740950214\n",
      "67.86956787109375\n",
      "41.49664306640625 66.30725609998866\n",
      "87.7950439453125\n",
      "59.38671875 69.93280870737878\n",
      "94.5458984375\n",
      "52.7703857421875 74.30941474250847\n",
      "93.68701171875\n",
      "59.6749267578125 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "new_data = os.path.join(PROCESSED_DATA, \"train_set\")\n",
    "folder = os.path.join(new_data, \"1\")\n",
    "for x in os.listdir(folder)[:10]:\n",
    "    path = os.path.join(folder, x)\n",
    "    print(numpy_model(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_samples(processed_data=True):\n",
    "    \"\"\"\n",
    "    gather all files from all folders\n",
    "\n",
    "    :type: str representing which files we want\n",
    "    :return: list containg a list for each sample with the path and the category\n",
    "    \"\"\"\n",
    "\n",
    "    if processed_data:\n",
    "        data_folder = PROCESSED_DATA\n",
    "        templates = [1,2,3,4,5,6]\n",
    "    else:\n",
    "        data_folder = DATA_FOLDER\n",
    "        template_folder = os.path.join(DATA_FOLDER, \"train_set\")\n",
    "        templates = os.listdir(template_folder)\n",
    "\n",
    "    all_files = []\n",
    "\n",
    "    for template in templates:\n",
    "\n",
    "        # get the folder name, all filenames inside it, and make a list of all the image files inside\n",
    "        train_folder = os.path.join(data_folder, 'train_set')\n",
    "        folder = os.path.join(train_folder, str(template))\n",
    "        filenames = os.listdir(folder)\n",
    "        files = [file for file in filenames if \".png\" in file]\n",
    "\n",
    "        for file in files:\n",
    "            random_file_path = os.path.join(folder,file)\n",
    "\n",
    "            all_files.append([random_file_path, template])\n",
    "\n",
    "    return all_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = gather_samples()\n",
    "\n",
    "df = pd.DataFrame(all_files)\n",
    "df = df.set_axis(['path', 'category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code below calculates the errors for each of the categories.\n",
    "\n",
    "def train_model(processed_data = True, matching_method = \"pixel_count\"):\n",
    "    \"\"\"\n",
    "    A very basic model where each sample n has x features that represent the error per category\n",
    "    calculated by the match template - pixel count method.\n",
    "\n",
    "    :returns: a list containing a list for each sample containing x errors, 1 for each category. \n",
    "    \"\"\"\n",
    "\n",
    "    if processed_data:\n",
    "        template_folder = TEMPLATE_FOLDER\n",
    "        all_templates = os.listdir(TEMPLATE_FOLDER)\n",
    "    else:\n",
    "        template_folder = os.path.join(DATA_FOLDER, \"templates\")\n",
    "        all_templates = os.listdir(template_folder)\n",
    "        all_templates.remove('ano.png')\n",
    "    \n",
    "    all_errors = []\n",
    "    # for each sample\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        sample_path = row['path']\n",
    "        errors_per_row = []\n",
    "\n",
    "        for idx, template in enumerate(all_templates):\n",
    "            category = template\n",
    "            category = category.replace(\".png\",\"\")\n",
    "            template_file = template\n",
    "            correct_template_path = os.path.join(template_folder, template_file)\n",
    "            errors, _, _ = match_template(sample_path, correct_template_path, category, method = matching_method)\n",
    "            errors_per_row.append(errors)\n",
    "        all_errors.append(errors_per_row)\n",
    "\n",
    "    return all_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying with adaptive threshold per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather processed data\n",
    "all_files = gather_samples(processed_data=True)\n",
    "\n",
    "df = pd.DataFrame(all_files)\n",
    "df = df.set_axis(['path', 'category'], axis=1)\n",
    "\n",
    "# gather all anomaly files \n",
    "anom_files = []\n",
    "\n",
    "train_folder = os.path.join(PROCESSED_DATA, 'train_set')\n",
    "folder = os.path.join(train_folder, \"ano\")\n",
    "filenames = os.listdir(folder)\n",
    "files = [file for file in filenames if \".png\" in file]\n",
    "\n",
    "for file in files:\n",
    "    random_file_path = os.path.join(folder,file)\n",
    "\n",
    "    anom_files.append([random_file_path,None])\n",
    "\n",
    "# gather some normal files \n",
    "normal_files = []\n",
    "\n",
    "train_folder = os.path.join(PROCESSED_DATA, 'train_set')\n",
    "for cat in [1,2,3,4,5,6]:\n",
    "    folder = os.path.join(train_folder, str(cat))\n",
    "    filenames = os.listdir(folder)\n",
    "    files = [file for file in filenames if \".png\" in file]\n",
    "    files = random.sample(files, 10)\n",
    "\n",
    "    for file in files:\n",
    "        random_file_path = os.path.join(folder,file)\n",
    "\n",
    "        normal_files.append([random_file_path,None])\n",
    "\n",
    "all_errors = train_model(matching_method=\"MSE\")\n",
    "\n",
    "results = pd.DataFrame(all_errors)\n",
    "results = results.transpose().reset_index(drop=True).transpose()\n",
    "results = results.set_axis([1,2,3,4,5,6], axis=1)\n",
    "\n",
    "df = pd.concat([df,results], axis=1)\n",
    "df.to_csv('results.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(image_path, processed_data = True, thresholds = [50 for x in range(11)]):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if processed_data:\n",
    "        template_folder = os.path.join(PROCESSED_DATA, \"templates\")\n",
    "        all_templates = os.listdir(template_folder)\n",
    "    else:\n",
    "        template_folder = os.path.join(DATA_FOLDER, \"templates\")\n",
    "        all_templates = os.listdir(template_folder)        \n",
    "\n",
    "    predicted = 0\n",
    "    predictions = []\n",
    "\n",
    "    for idx, template in enumerate(all_templates):\n",
    "        correct_template_path = os.path.join(TEMPLATE_FOLDER, template)\n",
    "        errors, _, _ = match_template(image_path, correct_template_path, category=idx+1, method=\"MSE\")\n",
    "        thresh = thresholds[idx+1]\n",
    "\n",
    "        if errors > thresh:\n",
    "            predictions.append(1)\n",
    "            predicted = 1\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "\n",
    "    return predicted, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 f1 :  0.8706031085000372 acc :  0.8706896551724138 roc :  0.8726190476190476 rand :  0.7744976432646986\n"
     ]
    }
   ],
   "source": [
    "coeff = 0.75\n",
    "\n",
    "thresholds = {}\n",
    "\n",
    "for x in range(6):\n",
    "    col = x+1\n",
    "\n",
    "    correct = df.loc[df.category == col]\n",
    "    false = df.loc[df.category != col]\n",
    "\n",
    "    correct_mean = correct[col].mean()\n",
    "    false_mean = false[col].mean()\n",
    "\n",
    "    thresholds[col] = (correct_mean + false_mean)*coeff\n",
    "\n",
    "template_folder = os.path.join(PROCESSED_DATA, \"templates\")\n",
    "all_templates = os.listdir(template_folder)\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "y_true = []\n",
    "\n",
    "for anom in anom_files:\n",
    "    prediction = 0\n",
    "    for idx, template in enumerate(all_templates):\n",
    "        category = idx + 1\n",
    "        template_file = template\n",
    "        correct_template_path = os.path.join(TEMPLATE_FOLDER, template_file)\n",
    "        pred, _ = model(anom[0], correct_template_path, thresholds)\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(1)\n",
    "\n",
    "for norm in normal_files:\n",
    "    prediction = 0\n",
    "    for idx, template in enumerate(all_templates):\n",
    "        category = idx + 1\n",
    "        template_file = template\n",
    "        correct_template_path = os.path.join(TEMPLATE_FOLDER, template_file)\n",
    "        pred, _ = model(norm[0], correct_template_path, thresholds)\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(0)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import rand_score\n",
    "print(coeff, 'f1 : ', f1_score(y_true, y_pred, average='macro'),\"acc : \",accuracy_score(y_true, y_pred),\"roc : \", roc_auc_score(y_true, y_pred),\"rand : \", rand_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('thresholds.pickle', 'wb') as handle:\n",
    "    pickle.dump(thresholds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 62.02780473883087,\n",
       " 2: 60.430025740950214,\n",
       " 3: 66.30725609998866,\n",
       " 4: 69.93280870737878,\n",
       " 5: 74.30941474250847,\n",
       " 6: 82.75002536741725}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.png', '2.png', '3.png', '4.png', '5.png', '6.png']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_folder = os.path.join(PROCESSED_DATA, \"templates\")\n",
    "os.listdir(template_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_model(image, path=True, thresholds=None):\n",
    "    \"\"\"\n",
    "    predicts whether a dice is an anomaly or not\n",
    "\n",
    "    :image: str path to image file\n",
    "    :thresholds: dict containg custom thresholds foe each category, load it in from thresholds.pickle\n",
    "    :return: return a predictions overall, and a prediction list as to what class it may belong\n",
    "    \"\"\"\n",
    "\n",
    "    all_templates = [\"1.png\", \"2.png\", \"3.png\", \"4.png\", \"5.png\", \"6.png\"]\n",
    "\n",
    "    predicted = 0\n",
    "    predictions = []\n",
    "\n",
    "    if not thresholds:\n",
    "        thresholds = {\n",
    "            1: 62.02780473883087,\n",
    "            2: 60.430025740950214,\n",
    "            3: 66.30725609998866,\n",
    "            4: 69.93280870737878,\n",
    "            5: 74.30941474250847,\n",
    "            6: 82.75002536741725,\n",
    "        }\n",
    "\n",
    "    for idx, template in enumerate(all_templates):\n",
    "        # this should link to a folder containg the templates.\n",
    "        template_path = os.path.join(TEMPLATE_FOLDER, template)\n",
    "\n",
    "        errors, _, _ = match_template(\n",
    "            image, template_path, path=path, category=1, method=\"MSE\"\n",
    "        )\n",
    "        thresh = thresholds[idx + 1]\n",
    "\n",
    "        print(errors, thresh)\n",
    "\n",
    "        if errors > thresh:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "\n",
    "    if sum(predictions) >= 6:\n",
    "        predicted = 1\n",
    "\n",
    "    return predicted, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse\n",
      "35.5228271484375 62.02780473883087\n",
      "mse\n",
      "52.44366455078125 60.430025740950214\n",
      "mse\n",
      "50.23321533203125 66.30725609998866\n",
      "mse\n",
      "56.977294921875 69.93280870737878\n",
      "mse\n",
      "54.762451171875 74.30941474250847\n",
      "mse\n",
      "62.4407958984375 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "mse\n",
      "48.64520263671875 62.02780473883087\n",
      "mse\n",
      "58.8927001953125 60.430025740950214\n",
      "mse\n",
      "58.71630859375 66.30725609998866\n",
      "mse\n",
      "61.30950927734375 69.93280870737878\n",
      "mse\n",
      "61.97613525390625 74.30941474250847\n",
      "mse\n",
      "65.86077880859375 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "mse\n",
      "36.89691162109375 62.02780473883087\n",
      "mse\n",
      "45.8560791015625 60.430025740950214\n",
      "mse\n",
      "37.24365234375 66.30725609998866\n",
      "mse\n",
      "54.30267333984375 69.93280870737878\n",
      "mse\n",
      "49.84185791015625 74.30941474250847\n",
      "mse\n",
      "53.51910400390625 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "mse\n",
      "44.870361328125 62.02780473883087\n",
      "mse\n",
      "48.71258544921875 60.430025740950214\n",
      "mse\n",
      "47.27459716796875 66.30725609998866\n",
      "mse\n",
      "54.0482177734375 69.93280870737878\n",
      "mse\n",
      "53.3214111328125 74.30941474250847\n",
      "mse\n",
      "53.9534912109375 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "mse\n",
      "40.58465576171875 62.02780473883087\n",
      "mse\n",
      "54.9879150390625 60.430025740950214\n",
      "mse\n",
      "52.6280517578125 66.30725609998866\n",
      "mse\n",
      "57.31439208984375 69.93280870737878\n",
      "mse\n",
      "54.35064697265625 74.30941474250847\n",
      "mse\n",
      "63.11322021484375 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "mse\n",
      "38.886474609375 62.02780473883087\n",
      "mse\n",
      "55.22686767578125 60.430025740950214\n",
      "mse\n",
      "52.99249267578125 66.30725609998866\n",
      "mse\n",
      "57.1875 69.93280870737878\n",
      "mse\n",
      "54.500732421875 74.30941474250847\n",
      "mse\n",
      "63.839111328125 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "mse\n",
      "39.51080322265625 62.02780473883087\n",
      "mse\n",
      "55.0172119140625 60.430025740950214\n",
      "mse\n",
      "52.82177734375 66.30725609998866\n",
      "mse\n",
      "58.03778076171875 69.93280870737878\n",
      "mse\n",
      "54.37799072265625 74.30941474250847\n",
      "mse\n",
      "63.73602294921875 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "mse\n",
      "40.91400146484375 62.02780473883087\n",
      "mse\n",
      "56.1021728515625 60.430025740950214\n",
      "mse\n",
      "53.453857421875 66.30725609998866\n",
      "mse\n",
      "57.74908447265625 69.93280870737878\n",
      "mse\n",
      "55.11822509765625 74.30941474250847\n",
      "mse\n",
      "64.07647705078125 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "mse\n",
      "42.76171875 62.02780473883087\n",
      "mse\n",
      "53.01007080078125 60.430025740950214\n",
      "mse\n",
      "43.94256591796875 66.30725609998866\n",
      "mse\n",
      "56.672119140625 69.93280870737878\n",
      "mse\n",
      "49.478515625 74.30941474250847\n",
      "mse\n",
      "55.5845947265625 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n",
      "mse\n",
      "37.0281982421875 62.02780473883087\n",
      "mse\n",
      "48.95648193359375 60.430025740950214\n",
      "mse\n",
      "41.49664306640625 66.30725609998866\n",
      "mse\n",
      "59.38671875 69.93280870737878\n",
      "mse\n",
      "52.7703857421875 74.30941474250847\n",
      "mse\n",
      "59.6749267578125 82.75002536741725\n",
      "(0, [0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "new_data = os.path.join(PROCESSED_DATA, \"train_set\")\n",
    "folder = os.path.join(new_data, \"1\")\n",
    "for x in os.listdir(folder)[:10]:\n",
    "    path = os.path.join(folder, x)\n",
    "    print(numpy_model(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(0, [1, 1, 1, 1, 1, 0])\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(0, [1, 1, 1, 1, 1, 0])\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(0, [1, 1, 1, 1, 1, 0])\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(0, [1, 1, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "new_data = os.path.join(PROCESSED_DATA, ('alber test'))\n",
    "proc_data = os.path.join(new_data, ('proc'))\n",
    "for x in os.listdir(proc_data):\n",
    "    path = os.path.join(proc_data, x)\n",
    "    print(numpy_model(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for x in normal_files:\n",
    "    res = numpy_model(x[0])\n",
    "    y_pred.append(res[0])\n",
    "    y_true.append(0)\n",
    "\n",
    "for x in anom_files:\n",
    "    res = numpy_model(x[0])\n",
    "    y_pred.append(res[0])\n",
    "    y_true.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 f1 :  0.9051089462333606 acc :  0.9051724137931034 roc :  0.9053571428571427 rand :  0.8268365817091454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import rand_score\n",
    "print(coeff, 'f1 : ', f1_score(y_true, y_pred, average='macro'),\"acc : \",accuracy_score(y_true, y_pred),\"roc : \", roc_auc_score(y_true, y_pred),\"rand : \", rand_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying with mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather processed data\n",
    "all_files = gather_samples(processed_data=True)\n",
    "\n",
    "df = pd.DataFrame(all_files)\n",
    "df = df.set_axis(['path', 'category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all anomaly files \n",
    "anom_files = []\n",
    "\n",
    "train_folder = os.path.join(PROCESSED_DATA, 'train_set')\n",
    "folder = os.path.join(train_folder, \"ano\")\n",
    "filenames = os.listdir(folder)\n",
    "files = [file for file in filenames if \".png\" in file]\n",
    "\n",
    "for file in files:\n",
    "    random_file_path = os.path.join(folder,file)\n",
    "\n",
    "    anom_files.append([random_file_path,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all anomaly files \n",
    "normal_files = []\n",
    "\n",
    "train_folder = os.path.join(PROCESSED_DATA, 'train_set')\n",
    "for cat in [1,2,3,4,5,6]:\n",
    "    folder = os.path.join(train_folder, str(cat))\n",
    "    filenames = os.listdir(folder)\n",
    "    files = [file for file in filenames if \".png\" in file]\n",
    "    files = random.sample(files, 10)\n",
    "\n",
    "    for file in files:\n",
    "        random_file_path = os.path.join(folder,file)\n",
    "\n",
    "        normal_files.append([random_file_path,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>category</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\processed_data\\train_set\\1\\16_09_21_00_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>35.522827</td>\n",
       "      <td>52.443665</td>\n",
       "      <td>50.233215</td>\n",
       "      <td>56.977295</td>\n",
       "      <td>54.762451</td>\n",
       "      <td>62.440796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\processed_data\\train_set\\1\\16_09_21_00_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>48.645203</td>\n",
       "      <td>58.892700</td>\n",
       "      <td>58.716309</td>\n",
       "      <td>61.309509</td>\n",
       "      <td>61.976135</td>\n",
       "      <td>65.860779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\processed_data\\train_set\\1\\16_09_21_00_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>36.896912</td>\n",
       "      <td>45.856079</td>\n",
       "      <td>37.243652</td>\n",
       "      <td>54.302673</td>\n",
       "      <td>49.841858</td>\n",
       "      <td>53.519104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\processed_data\\train_set\\1\\16_09_21_00_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>44.870361</td>\n",
       "      <td>48.712585</td>\n",
       "      <td>47.274597</td>\n",
       "      <td>54.048218</td>\n",
       "      <td>53.321411</td>\n",
       "      <td>53.953491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\processed_data\\train_set\\1\\16_09_21_00_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.584656</td>\n",
       "      <td>54.987915</td>\n",
       "      <td>52.628052</td>\n",
       "      <td>57.314392</td>\n",
       "      <td>54.350647</td>\n",
       "      <td>63.113220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  category          1  \\\n",
       "0  ..\\..\\processed_data\\train_set\\1\\16_09_21_00_0...         1  35.522827   \n",
       "1  ..\\..\\processed_data\\train_set\\1\\16_09_21_00_0...         1  48.645203   \n",
       "2  ..\\..\\processed_data\\train_set\\1\\16_09_21_00_0...         1  36.896912   \n",
       "3  ..\\..\\processed_data\\train_set\\1\\16_09_21_00_0...         1  44.870361   \n",
       "4  ..\\..\\processed_data\\train_set\\1\\16_09_21_00_0...         1  40.584656   \n",
       "\n",
       "           2          3          4          5          6  \n",
       "0  52.443665  50.233215  56.977295  54.762451  62.440796  \n",
       "1  58.892700  58.716309  61.309509  61.976135  65.860779  \n",
       "2  45.856079  37.243652  54.302673  49.841858  53.519104  \n",
       "3  48.712585  47.274597  54.048218  53.321411  53.953491  \n",
       "4  54.987915  52.628052  57.314392  54.350647  63.113220  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_errors = train_model(matching_method=\"MSE\")\n",
    "\n",
    "results = pd.DataFrame(all_errors)\n",
    "results = results.transpose().reset_index(drop=True).transpose()\n",
    "results = results.set_axis([1,2,3,4,5,6], axis=1)\n",
    "\n",
    "df = pd.concat([df,results], axis=1)\n",
    "df.to_csv('results.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.618622778552197 53.085116873222304\n",
      "31.468391180038452 49.10497647456184\n",
      "38.14536787823933 50.26430692174555\n",
      "39.7240070785064 53.5197378646653\n",
      "44.042650235409766 55.036569421268204\n",
      "50.06285226605105 60.27051489050528\n"
     ]
    }
   ],
   "source": [
    "thresholds = {}\n",
    "\n",
    "for x in range(6):\n",
    "    col = x+1\n",
    "\n",
    "    correct = df.loc[df.category == col]\n",
    "    false = df.loc[df.category != col]\n",
    "    \n",
    "    print(correct[col].mean(), false[col].mean())\n",
    "\n",
    "    thresholds[col] = (correct[col].mean() + false[col].mean())/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.195259488563806"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average = 0\n",
    "for key, val in thresholds.items():\n",
    "    average += val\n",
    "\n",
    "average = average\n",
    "average = average / 6\n",
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71 f1 :  0.8619047619047618 acc :  0.8620689655172413 roc :  0.8642857142857143 rand :  0.7618456958571074\n",
      "0.72 f1 :  0.896551724137931 acc :  0.896551724137931 roc :  0.8976190476190476 rand :  0.8142396427685438\n",
      "0.73 f1 :  0.9137674695212608 acc :  0.9137931034482759 roc :  0.9142857142857144 rand :  0.8422227735053337\n",
      "0.74 f1 :  0.9137674695212608 acc :  0.9137931034482759 roc :  0.9142857142857144 rand :  0.8422227735053337\n",
      "0.75 f1 :  0.9223618651000223 acc :  0.9224137931034483 roc :  0.9226190476190476 rand :  0.8566608781939965\n",
      "0.76 f1 :  0.9222693768148315 acc :  0.9224137931034483 roc :  0.9220238095238095 rand :  0.8566608781939965\n",
      "0.77 f1 :  0.9048258372491982 acc :  0.9051724137931034 roc :  0.9041666666666667 rand :  0.8280823616968495\n",
      "0.78 f1 :  0.8960573476702509 acc :  0.896551724137931 roc :  0.8952380952380953 rand :  0.8142396427685438\n",
      "0.79 f1 :  0.8695163104611923 acc :  0.8706896551724138 roc :  0.868452380952381 rand :  0.7744976432646986\n",
      "0.8 f1 :  0.8515842552871227 acc :  0.853448275862069 roc :  0.8505952380952381 rand :  0.7494914413296949\n",
      "0.81 f1 :  0.8149920255183412 acc :  0.8189655172413793 roc :  0.8148809523809524 rand :  0.7030513520218308\n",
      "0.8200000000000001 f1 :  0.7674992291088498 acc :  0.7758620689655172 roc :  0.7702380952380953 rand :  0.6516993301910196\n",
      "0.8300000000000001 f1 :  0.7436868686868687 acc :  0.7586206896551724 roc :  0.7511904761904761 rand :  0.6332423716199455\n",
      "0.8400000000000001 f1 :  0.7014157014157014 acc :  0.7241379310344828 roc :  0.7154761904761905 rand :  0.5999007690399405\n",
      "0.8500000000000001 f1 :  0.7014157014157014 acc :  0.7241379310344828 roc :  0.7154761904761905 rand :  0.5999007690399405\n",
      "0.8600000000000001 f1 :  0.675657894736842 acc :  0.7068965517241379 roc :  0.6970238095238095 rand :  0.5850161250310096\n",
      "0.8700000000000001 f1 :  0.6354989384288747 acc :  0.6810344827586207 roc :  0.6696428571428572 rand :  0.5649218556189531\n",
      "0.8800000000000001 f1 :  0.5972222222222222 acc :  0.6551724137931034 roc :  0.6428571428571428 rand :  0.5475068221285041\n",
      "0.8900000000000001 f1 :  0.5423242467718795 acc :  0.6206896551724138 roc :  0.6071428571428571 rand :  0.5284544777970727\n",
      "0.9000000000000001 f1 :  0.4977429755872869 acc :  0.5948275862068966 roc :  0.5803571428571429 rand :  0.5172909947903745\n"
     ]
    }
   ],
   "source": [
    "template_folder = os.path.join(PROCESSED_DATA, \"templates\")\n",
    "all_templates = os.listdir(template_folder)\n",
    "\n",
    "coeff = 0.7\n",
    "\n",
    "for x in range(20):\n",
    "\n",
    "    coeff += 0.01\n",
    "\n",
    "    thresholds = {}\n",
    "\n",
    "    for x in range(6):\n",
    "        col = x+1\n",
    "\n",
    "        correct = df.loc[df.category == col]\n",
    "        false = df.loc[df.category != col]\n",
    "\n",
    "        thresholds[col] = (correct[col].mean() + false[col].mean())*coeff\n",
    "\n",
    "    y_pred = []\n",
    "\n",
    "    y_true = []\n",
    "\n",
    "    for anom in anom_files:\n",
    "        prediction = 0\n",
    "        for idx, template in enumerate(all_templates):\n",
    "            category = idx + 1\n",
    "            template_file = template\n",
    "            correct_template_path = os.path.join(TEMPLATE_FOLDER, template_file)\n",
    "            pred, _ = model(anom[0], correct_template_path, thresholds)\n",
    "            y_pred.append(pred)\n",
    "            y_true.append(1)\n",
    "\n",
    "\n",
    "\n",
    "    for anom in normal_files:\n",
    "        prediction = 0\n",
    "        for idx, template in enumerate(all_templates):\n",
    "            category = idx + 1\n",
    "            template_file = template\n",
    "            correct_template_path = os.path.join(TEMPLATE_FOLDER, template_file)\n",
    "            pred, _ = model(anom[0], correct_template_path, thresholds)\n",
    "            y_pred.append(pred)\n",
    "            y_true.append(0)\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import rand_score\n",
    "    print(coeff, 'f1 : ', f1_score(y_true, y_pred, average='macro'),\"acc : \",accuracy_score(y_true, y_pred),\"roc : \", roc_auc_score(y_true, y_pred),\"rand : \", rand_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors = train_model()\n",
    "\n",
    "results = pd.DataFrame(all_errors)\n",
    "results = results.transpose().reset_index(drop=True).transpose()\n",
    "results = results.set_axis([1,2,3,4,5,6], axis=1)\n",
    "\n",
    "df = pd.concat([df,results], axis=1)\n",
    "df.to_csv('results.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5077.420624151968 5529.879499485773\n",
      "5736.462890625 6387.752478817379\n",
      "5769.956910569105 6368.983710915559\n",
      "5832.717811158798 6556.790920375953\n",
      "5771.823399558499 6686.0946160635485\n",
      "5733.020665901263 7280.811141022986\n"
     ]
    }
   ],
   "source": [
    "thresholds = {}\n",
    "\n",
    "for x in range(6):\n",
    "    col = x+1\n",
    "\n",
    "    correct = df.loc[df.category == col]\n",
    "    false = df.loc[df.category != col]\n",
    "    \n",
    "    print(correct[col].mean(), false[col].mean())\n",
    "\n",
    "    thresholds[col] = (correct[col].mean() + false[col].mean())/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 5303.65006181887,\n",
       " 2: 6062.10768472119,\n",
       " 3: 6069.470310742332,\n",
       " 4: 6194.754365767376,\n",
       " 5: 6228.959007811023,\n",
       " 6: 6506.915903462124}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = 0\n",
    "for key, val in thresholds.items():\n",
    "    average += val\n",
    "\n",
    "average = average - 500\n",
    "average = average / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all anomaly files \n",
    "anom_files = []\n",
    "\n",
    "train_folder = os.path.join(PROCESSED_DATA, 'train_set')\n",
    "folder = os.path.join(train_folder, \"ano\")\n",
    "filenames = os.listdir(folder)\n",
    "files = [file for file in filenames if \".png\" in file]\n",
    "\n",
    "for file in files:\n",
    "    random_file_path = os.path.join(folder,file)\n",
    "\n",
    "    anom_files.append([random_file_path, template])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "total_detection = 0\n",
    "\n",
    "for anom in anom_files:\n",
    "    prediction = 0\n",
    "    for idx, template in enumerate(all_templates):\n",
    "        category = idx + 1\n",
    "        template_file = template\n",
    "        correct_template_path = os.path.join(TEMPLATE_FOLDER, template_file)\n",
    "        errors, _, _ = match_template(anom[0], correct_template_path, category)\n",
    "        if errors > average:\n",
    "            prediction = 1\n",
    "    predictions.append(prediction)\n",
    "\n",
    "correct_predictions = [1 for x in predictions]\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(correct_predictions, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = [1 for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(correct_predictions, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try with the old images\n",
    "all_files = gather_samples(processed_data=False)\n",
    "\n",
    "df = pd.DataFrame(all_files)\n",
    "df = df.set_axis(['path', 'category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors = train_model(processed_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>category</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\data\\train_set\\00\\16_09_21_00_000.png</td>\n",
       "      <td>00</td>\n",
       "      <td>5212</td>\n",
       "      <td>6575</td>\n",
       "      <td>6435</td>\n",
       "      <td>7241</td>\n",
       "      <td>6962</td>\n",
       "      <td>7876</td>\n",
       "      <td>8134</td>\n",
       "      <td>10128</td>\n",
       "      <td>9965</td>\n",
       "      <td>10064</td>\n",
       "      <td>10176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data\\train_set\\00\\16_09_21_00_001.png</td>\n",
       "      <td>00</td>\n",
       "      <td>7718</td>\n",
       "      <td>7810</td>\n",
       "      <td>8564</td>\n",
       "      <td>8488</td>\n",
       "      <td>9142</td>\n",
       "      <td>9239</td>\n",
       "      <td>9321</td>\n",
       "      <td>12242</td>\n",
       "      <td>12369</td>\n",
       "      <td>11866</td>\n",
       "      <td>12491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\data\\train_set\\00\\16_09_21_00_002.png</td>\n",
       "      <td>00</td>\n",
       "      <td>2547</td>\n",
       "      <td>5038</td>\n",
       "      <td>4951</td>\n",
       "      <td>5853</td>\n",
       "      <td>4696</td>\n",
       "      <td>7310</td>\n",
       "      <td>7227</td>\n",
       "      <td>8043</td>\n",
       "      <td>8479</td>\n",
       "      <td>8138</td>\n",
       "      <td>8663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\data\\train_set\\00\\16_09_21_00_003.png</td>\n",
       "      <td>00</td>\n",
       "      <td>2329</td>\n",
       "      <td>4782</td>\n",
       "      <td>4542</td>\n",
       "      <td>5059</td>\n",
       "      <td>4336</td>\n",
       "      <td>6893</td>\n",
       "      <td>6905</td>\n",
       "      <td>7885</td>\n",
       "      <td>8254</td>\n",
       "      <td>8400</td>\n",
       "      <td>8276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\data\\train_set\\00\\16_09_21_00_004.png</td>\n",
       "      <td>00</td>\n",
       "      <td>3795</td>\n",
       "      <td>5476</td>\n",
       "      <td>5726</td>\n",
       "      <td>6524</td>\n",
       "      <td>5837</td>\n",
       "      <td>7495</td>\n",
       "      <td>7561</td>\n",
       "      <td>9945</td>\n",
       "      <td>9539</td>\n",
       "      <td>9579</td>\n",
       "      <td>9929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          path category     1     2     3  \\\n",
       "0  ..\\..\\data\\train_set\\00\\16_09_21_00_000.png       00  5212  6575  6435   \n",
       "1  ..\\..\\data\\train_set\\00\\16_09_21_00_001.png       00  7718  7810  8564   \n",
       "2  ..\\..\\data\\train_set\\00\\16_09_21_00_002.png       00  2547  5038  4951   \n",
       "3  ..\\..\\data\\train_set\\00\\16_09_21_00_003.png       00  2329  4782  4542   \n",
       "4  ..\\..\\data\\train_set\\00\\16_09_21_00_004.png       00  3795  5476  5726   \n",
       "\n",
       "      4     5     6     7      8      9     10     11  \n",
       "0  7241  6962  7876  8134  10128   9965  10064  10176  \n",
       "1  8488  9142  9239  9321  12242  12369  11866  12491  \n",
       "2  5853  4696  7310  7227   8043   8479   8138   8663  \n",
       "3  5059  4336  6893  6905   7885   8254   8400   8276  \n",
       "4  6524  5837  7495  7561   9945   9539   9579   9929  "
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(all_errors)\n",
    "results = results.transpose().reset_index(drop=True).transpose()\n",
    "results = results.set_axis([1,2,3,4,5,6,7,8,9,10,11], axis=1)\n",
    "\n",
    "df = pd.concat([df,results], axis=1)\n",
    "df.to_csv('results.csv')\n",
    "df = df[df.category != \"ano\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'] = pd.to_numeric(df.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8503.953703703704 8180.433758912286\n",
      "9335.028925619834 9155.987021521274\n",
      "9064.86303630363 9183.330427493713\n",
      "9822.004807692309 9802.97948545485\n",
      "9311.492489270386 9663.397942897676\n",
      "8987.030905077263 10396.141394527802\n",
      "10920.125907990314 10235.96346216304\n",
      "10825.793969849246 12040.647011177709\n",
      "10877.939334637966 11959.446864686468\n",
      "10932.016666666666 11982.497317509347\n"
     ]
    }
   ],
   "source": [
    "thresholds = {}\n",
    "\n",
    "for x in range(10):\n",
    "    col = x+1\n",
    "\n",
    "    correct = df.loc[df.category == col]\n",
    "    false = df.loc[df.category != col]\n",
    "    \n",
    "    print(correct[col].mean(), false[col].mean())\n",
    "\n",
    "    thresholds[col] = (correct[col].mean() + false[col].mean())/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 8342.193731307994,\n",
       " 2: 9245.507973570555,\n",
       " 3: 9124.096731898671,\n",
       " 4: 9812.492146573579,\n",
       " 5: 9487.44521608403,\n",
       " 6: 9691.586149802533,\n",
       " 7: 10578.044685076677,\n",
       " 8: 11433.220490513479,\n",
       " 9: 11418.693099662218,\n",
       " 10: 11457.256992088007}"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = 0\n",
    "for key, val in thresholds.items():\n",
    "    average += val\n",
    "\n",
    "average = average - 500\n",
    "average = average / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10009.053721657776"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all anomaly files \n",
    "anom_files = []\n",
    "\n",
    "train_folder = os.path.join(DATA_FOLDER, 'train_set')\n",
    "folder = os.path.join(train_folder, \"ano\")\n",
    "filenames = os.listdir(folder)\n",
    "files = [file for file in filenames if \".png\" in file]\n",
    "\n",
    "for file in files:\n",
    "    random_file_path = os.path.join(folder,file)\n",
    "\n",
    "    anom_files.append([random_file_path, template])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4042553191489362"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_folder = os.path.join(DATA_FOLDER, \"templates\")\n",
    "all_templates = os.listdir(template_folder)\n",
    "all_templates.remove('ano.png')\n",
    "\n",
    "predictions = []\n",
    "total_detection = 0\n",
    "\n",
    "for anom in anom_files:\n",
    "    prediction = 0\n",
    "    for idx, template in enumerate(all_templates):\n",
    "        category = template\n",
    "        category = category.replace('.png', '')\n",
    "        template_file = template\n",
    "        correct_template_path = os.path.join(template_folder, template_file)\n",
    "        errors, _, _ = match_template(anom[0], correct_template_path, category)\n",
    "        if errors > average:\n",
    "            prediction = 1\n",
    "    predictions.append(prediction)\n",
    "\n",
    "correct_predictions = [1 for x in predictions]\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(correct_predictions, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fd65506147fe4f66ad28d9813792ae1a36a4062b2d7e2e39e3b9ce41d2e0a83"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('dicething': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
